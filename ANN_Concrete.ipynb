{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing Data from google drive**\n",
        "\n",
        "The location of the project is '/content/drive/MyDrive/concrete_ai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQWc19zXNH5t",
        "outputId": "52e6d5f0-4a08-41cf-c0ba-6df8e2720752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "current directory :  /content/drive/MyDrive/concrete_ai\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/concrete_ai')\n",
        "cwd = os.getcwd()\n",
        "print('current directory : ', cwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing libraries**\n",
        "\n",
        "that includes (keras, numpy, pandas and tensorflow)\n",
        "\n",
        "also used custom classes like \n",
        "- data : for data loading\n",
        "- utils : for setuping the model\n",
        "- printing_callback : for good visualization of results while training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ju74GThNNCd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from utils import utils\n",
        "import tensorflow as tf\n",
        "import printing_callback as callback\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LayerNormalization, Dropout\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting the random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0XfYeN7iAq8"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Settings the input excel files path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgqWFQpwNPl6"
      },
      "outputs": [],
      "source": [
        "INPUT_TITLE = 'additives2'\n",
        "OUTPUT_TITLE = 'additives2_28days'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data proccessing**\n",
        "\n",
        "Data loading, removing old files and division into training, testing and validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "763PldUINSW5",
        "outputId": "09748499-ddcb-4311-d9d6-d7b40f54de29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading the data ...\n",
            "data loaded with size:  (1075, 16) \n",
            "\n",
            "\n",
            "there is Nan in data\n",
            "\n",
            "\n",
            "shuffling the data ...\n",
            "data shuffled\n",
            "\n",
            "\n",
            "dividing the data ...\n",
            "training data ready with size: (753, 16)\n",
            "test data ready with size: (162, 16)\n",
            "validation data ready with size: (160, 16)\n",
            "data ready with train: (350, 13) and test: (72, 13) and validation: (73, 13)\n"
          ]
        }
      ],
      "source": [
        "train , test, validation = data.getFinalData('data_files/' + INPUT_TITLE + '.xlsx')\n",
        "train, test, validation = data.prepareMultipleData(train, test, validation, [12, 13, 14])\n",
        "\n",
        "tmp1 = train.shape[1] - 1\n",
        "tmp2 = train.shape[1]\n",
        " \n",
        "xr = train[:,0:tmp1]\n",
        "yr = train[:,tmp1:tmp2]\n",
        "xt = test[:,0:tmp1]\n",
        "yt = test[:,tmp1:tmp2]\n",
        "xv = validation[:,0:tmp1]\n",
        "yv = validation[:,tmp1:tmp2]\n",
        " \n",
        "utils.exceptionIfNan(train)\n",
        "utils.exceptionIfNan(test)\n",
        "utils.exceptionIfNan(validation)\n",
        " \n",
        "print('data ready with train:', train.shape, 'and test:', test.shape,\n",
        "      'and validation:', validation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setting up the new modle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FbQIrc2OSsP"
      },
      "outputs": [],
      "source": [
        "model = utils.newSeqentialModel(xr.shape[1], yr.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading previously saved weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhJF8_epN3pD",
        "outputId": "5524ed0d-c770-498b-9dc4-bbcc2f2802c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading model weights ...\n",
            "model weights loaded\n"
          ]
        }
      ],
      "source": [
        "print('loading model weights ...')\n",
        "output_dir = os.path.join(os.getcwd(), \"saved_wights\")\n",
        "try:\n",
        "    model.load_weights(filepath=os.path.join(output_dir, OUTPUT_TITLE + \".h5\"))\n",
        "    print('model weights loaded')\n",
        "except OSError:\n",
        "    print('no previous weights found')\n",
        "except ValueError:\n",
        "    print('previous weights are different from current') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RZJgyQNfml",
        "outputId": "dea7b754-7bc0-4d0f-a5ee-0b67802cfbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainning model using ANN\n",
            "\n",
            "epoch 0 : loss :   32.89 , MPE :   12.75. validation loss :   29.64 , MPE :   12.49\n",
            "epoch 100 : loss :   19.05 , MPE :    9.89. validation loss :   26.00 , MPE :   11.37\n",
            "epoch 200 : loss :   20.26 , MPE :    9.97. validation loss :   25.86 , MPE :   10.81\n",
            "epoch 300 : loss :   19.23 , MPE :    9.46. validation loss :   30.42 , MPE :   12.14\n",
            "epoch 400 : loss :   17.80 , MPE :    9.38. validation loss :   29.69 , MPE :   11.61\n",
            "epoch 500 : loss :   17.33 , MPE :    9.45. validation loss :   34.72 , MPE :   12.86\n",
            "epoch 600 : loss :   15.07 , MPE :    8.53. validation loss :   34.11 , MPE :   12.85\n",
            "epoch 700 : loss :   17.53 , MPE :    9.10. validation loss :   34.26 , MPE :   12.59\n",
            "epoch 800 : loss :   15.64 , MPE :    8.69. validation loss :   32.71 , MPE :   12.41\n",
            "epoch 900 : loss :   14.85 , MPE :    8.29. validation loss :   40.37 , MPE :   13.78\n",
            "epoch 1000 : loss :   14.51 , MPE :    8.11. validation loss :   36.62 , MPE :   13.06\n",
            "\n",
            "model trained\n"
          ]
        }
      ],
      "source": [
        "print('Trainning model using ANN\\n')\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "model.fit(xr, yr, epochs=20000, batch_size=32, validation_data=(xv, yv), \n",
        "verbose=0, callbacks=[callback.LossAndErrorPrintingCallback(),\n",
        "                      tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000),])\n",
        "print('\\nmodel trained')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Evaluating the model accuracy in the training, validation, testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5BA6G2j7ls6",
        "outputId": "36f2f725-9a2f-49ce-addf-c269706410cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 132.4403 - mean_absolute_percentage_error: 24.6790\n",
            "\n",
            "Error on test data: 24.68\n"
          ]
        }
      ],
      "source": [
        "print('\\nmodel trained')\n",
        "_, accuracy_train = model.evaluate(xr, yr)\n",
        "print('\\nError in train data: %.2f' % (accuracy_train))\n",
        "\n",
        "_, accuracy_validation = model.evaluate(xv, yv)\n",
        "print('\\nError in validation data: %.2f' % (accuracy_validation))\n",
        "\n",
        "_, accuracy_test = model.evaluate(xt, yt)\n",
        "print('\\nError in test data: %.2f' % (accuracy_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Testing the model in 20 random samples from the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cafyZKoNrFS",
        "outputId": "ca1aba04-d565-4b46-dbeb-a2427244f124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " test: predicted: [29.2] real data: [31.8]\n",
            " test: predicted: [30.7] real data: [26.56666667]\n",
            " test: predicted: [29.6] real data: [28.7]\n",
            " test: predicted: [27.9] real data: [36.2]\n",
            " test: predicted: [27.7] real data: [32.03333333]\n",
            " test: predicted: [27.8] real data: [38.4]\n",
            " test: predicted: [28.9] real data: [34.7]\n",
            " test: predicted: [26.9] real data: [34.]\n",
            " test: predicted: [28.9] real data: [40.8]\n",
            " test: predicted: [27.5] real data: [50.83333333]\n",
            " test: predicted: [28.] real data: [45.2]\n",
            " test: predicted: [26.9] real data: [44.9]\n",
            " test: predicted: [27.7] real data: [43.8]\n",
            " test: predicted: [27.3] real data: [38.]\n",
            " test: predicted: [28.1] real data: [43.9]\n",
            " test: predicted: [28.6] real data: [31.7]\n",
            " test: predicted: [30.2] real data: [41.6]\n",
            " test: predicted: [27.5] real data: [30.8]\n",
            " test: predicted: [27.] real data: [45.23333333]\n",
            " test: predicted: [28.1] real data: [25.06666667]\n"
          ]
        }
      ],
      "source": [
        "test_predictions = np.around(model.predict(xt), 1)\n",
        " \n",
        "for i in range(20):\n",
        "    print(' test: predicted:', test_predictions[i], 'real data:', yt[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Saving the test set output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSEcdCNdNuOK",
        "outputId": "49fa2a53-a2e9-493e-ba4f-960dfafd2713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved data to excel file \n",
            "path: results/additives2_7days.xlsx\n"
          ]
        }
      ],
      "source": [
        "result = np.concatenate([xt, yt, test_predictions], axis=1)\n",
        "data.saveData(result, 'results/' + OUTPUT_TITLE +'.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Saving the model weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabIIHmQOEZF",
        "outputId": "e2a04c30-7e26-4758-c3f9-100eff7a04c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "saving model weights ...\n",
            "model weights saved\n"
          ]
        }
      ],
      "source": [
        "print('\\nsaving model weights ...')\n",
        "output_dir = os.path.join(os.getcwd(), \"saved_wights\")\n",
        "model.save_weights(filepath=os.path.join(output_dir, OUTPUT_TITLE + \".h5\"))\n",
        "print('model weights saved')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ANN Concrete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
